---
title: 全文搜索方法的使用
author: LY
date: 2019-09-26
summary: 记一次基于haystack的whoosh的全文搜索引擎框架的方法，该方法可用于大部分的中小型网站
categories:
    - 后端
tags:
    - 全文检索
    - Django
---



## 基于 haystack来使用whoosh检索引擎

这篇博客是基于Django来编写的案例，haystack可以自定义搜索，开发者可以通过haystack间接使用搜索引擎，并且他可以像DJango的ORM一样，只需改少量代码就可以自由切换引擎

这里拿haystack使用whoosh引擎来作为案例

### 基本安装和配置

首先先安装这两个包

```
pip install django-haystack
pip install whoosh
```

然后在setting.py注册应用haystack

![](https://txy-tc-ly-1256104767.cos.ap-guangzhou.myqcloud.com/18.png)



并且在setting.py文件添加如下字段：

```python
# 全文检索框架配置
HAYSTACK_CONNECTIONS = {
    'default': {
        # 使用whoosh引擎
        # 'ENGINE': 'haystack.backends.whoosh_backend.WhooshEngine',
        'ENGINE': 'haystack.backends.whoosh_backend.WhooshEngine',   
        # 索引文件路径
        'PATH': os.path.join(os.path.dirname(__file__), 'whoosh_index'),
    },
}

# 当添加、修改、删除数据时，自动生成索引
HAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor'
```

以上的是默认的配置，如果要添加jieba文字的话要另外配置

### 生成索引文件

在你要检索的模型类的那个包中，添加一个文件

如我要检索的是所有的商品文件：

![](https://txy-tc-ly-1256104767.cos.ap-guangzhou.myqcloud.com/19.png)

里面的search_indexes.py就是我写的文件

内容如下：

```python
from haystack import indexes
from goods.models import GoodsSKU

class GoodsSKUIndex(indexes.SearchIndex, indexes.Indexable):
    #索引字段document=True指定根据表的哪些字段简历索引文件制定在一个文件中
    text = indexes.CharField(document=True, use_template=True)
    # author = indexes.CharField(model_attr='user')
    # pub_date = indexes.DateTimeField(model_attr='pub_date')

    def get_model(self):
        return GoodsSKU

    # 建立索引数据
    def index_queryset(self, using=None):
        return self.get_model().objects.all()
        #返回所有数据就是对所有的数据进行索引
```

然后要定义你检索出来的那个界面

创建如下文件：

![](https://txy-tc-ly-1256104767.cos.ap-guangzhou.myqcloud.com/20.png)

goodssku_text.txt就是定义你可以检索的字段，我的检索字段如下：

```
# 指定根据表中的哪些字段建立索引数据
{{ object.name }}  # 根据商品的名称建立索引
{{ object.desc }}  # 根据商品的简介建立索引
{{ object.goods.detail }}  # 根据商品的详情建立索引
```

然后使用命令

```
python manage.py rebuild_index
```

这样会生成索引文件

如图：

![](https://txy-tc-ly-1256104767.cos.ap-guangzhou.myqcloud.com/21.png)



### 使用搜索功能

在搜索的那个表单上，填写内容如下

```
<form action="/search" method="get">

</form>
```

然后要添加url路径

```
url('search/', include('haystack.urls')),  # 全文检索框架
```

搜索完后结果会提交到一个search.html页面，会传递这几个变量

```
query：搜索关键字
page：当前页的page对象 –>遍历page对象，获取到的是SearchResult类的实例对象，对象的属性object才是模型类的对象。
paginator：分页paginator对象
```

然后自定义一个搜索列表的模板，将这三个变量使用Django传递变量的方式添加进去即可

### 汉语分词检索

如果是英文的话一个单词就是一个商品，但是汉语远远比英语复杂的多，比如搜索你好，可以分为你和好

Python有个jieba包可以帮助我们进行汉语分词

首先先安装jieba包

```
pip install jieba
```

要对原来的分词结果使用汉语分词的话就要对下载下来的包进行jieba分词

进入对pip下载的haystack包里面添加ChineseTokenizer.py文件，内容如下

```python
import jieba
from whoosh.analysis import Tokenizer, Token

class ChineseTokenizer(Tokenizer):
    def __call__(self, value, positions=False, chars=False,
                 keeporiginal=False, removestops=True,
                 start_pos=0, start_char=0, mode='', **kwargs):
        t = Token(positions, chars, removestops=removestops, mode=mode, **kwargs)
        seglist = jieba.cut(value, cut_all=True)
        for w in seglist:
            t.original = t.text = w
            t.boost = 1.0
            if positions:
                t.pos = start_pos + value.find(w)
            if chars:
                t.startchar = start_char + value.find(w)
                t.endchar = start_char + value.find(w) + len(w)
            yield t

def ChineseAnalyzer():
    return ChineseTokenizer()
```

然后拷贝原来的whoosh_backend.py文件，改名为whoosh_cn_backend.py

添加如下字段：

```python
#对原来导入的包添加
from .ChineseAnalyzer import ChineseAnalyzer

# 第163行的
# schema_fields[field_class.index_fieldname] = TEXT(stored=True, analyzer=StemmingAnalyzer(),      
# field_boost=field_class.boost, sortable=True)
# 改为


# schema_fields[field_class.index_fieldname] = TEXT(stored=True, analyzer=ChineseAnalyzer(),  
# field_boost=field_class.boost, sortable=True)
```

然后回去setting.py修改成'ENGINE': 'haystack.backends.whoosh_cn_backend.WhooshEngine'

然后再进行一次索引就可以使用汉语的jieba分词了